"""
Test rÃ¡pido de la integraciÃ³n completa con Hugging Face
"""
import asyncio
import httpx


import os

async def test():
    hf_token = os.environ.get("HF_API_TOKEN", "")
    model = "google/gemma-3-12b-it:featherless-ai"
    base_url = os.environ.get("HF_API_URL", "https://router.huggingface.co/v1")
    
    print("ğŸ¤— Test Final - Hugging Face + Gemma 3 12B")
    print("=" * 50)
    
    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(
            f"{base_url}/chat/completions",
            headers={
                "Authorization": f"Bearer {hf_token}",
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": "Responde en espaÃ±ol: Â¿QuÃ© es FastAPI y para quÃ© sirve?"
                    }
                ],
                "temperature": 0.7,
                "max_tokens": 200,
                "stream": False
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Status: {response.status_code}")
            print(f"ğŸ“¦ Modelo: {model}")
            print(f"\nğŸ’¬ Respuesta:")
            print("-" * 50)
            print(result["choices"][0]["message"]["content"])
            print("-" * 50)
            if "usage" in result:
                usage = result["usage"]
                print(f"\nğŸ“ˆ Tokens: prompt={usage.get('prompt_tokens', 'N/A')}, completion={usage.get('completion_tokens', 'N/A')}")
            print("\nğŸ‰ Â¡Todo funciona correctamente!")
        else:
            print(f"âŒ Error {response.status_code}: {response.text[:300]}")


if __name__ == "__main__":
    asyncio.run(test())
